## By Default English Language here (Important: Edit in UTF-8)

es.uned.nlp.evall.evallweb.portlet.evaluate.save=Save
es.uned.nlp.evall.evallweb.portlet.evaluate.save.output=Save in EvALL repository
es.uned.nlp.evall.evallweb.portlet.evaluate.back=Back
es.uned.nlp.evall.evallweb.portlet.evaluate.next.step=Next step
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.list.title=Select the benchmark you want to explore
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.clear.search=Clear filters
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.text.for.title=benchmark
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.details=Details
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.authors=Authors
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.links=Links
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.conference=Conference
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.workshop=Workshop
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.year=Year
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.task=Task
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.measure=Official measure
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.other.measure=Other official measures
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.website=Official WebSite
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.paper=URL Paper
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.bibtex=BibTex
es.uned.nlp.evall.evallweb.portlet.evaluate.benchmark.description=Description
es.uned.nlp.evall.evallweb.portlet.evaluate.system.details=Details
es.uned.nlp.evall.evallweb.portlet.evaluate.system.authors=Authors
es.uned.nlp.evall.evallweb.portlet.evaluate.system.links=Links
es.uned.nlp.evall.evallweb.portlet.evaluate.system.benchmark=Benchmark
es.uned.nlp.evall.evallweb.portlet.evaluate.system.task=Task
es.uned.nlp.evall.evallweb.portlet.evaluate.system.measure=Official measure
es.uned.nlp.evall.evallweb.portlet.evaluate.system.value=Value
es.uned.nlp.evall.evallweb.portlet.evaluate.system.date=Date
es.uned.nlp.evall.evallweb.portlet.evaluate.system.authors.title=Authors added
es.uned.nlp.evall.evallweb.portlet.evaluate.system.publication.title=Publication year
es.uned.nlp.evall.evallweb.portlet.evaluate.system.paper=Paper URL
es.uned.nlp.evall.evallweb.portlet.evaluate.system.bibtex=Paper bibTex
es.uned.nlp.evall.evallweb.portlet.evaluate.system.title=Paper title
es.uned.nlp.evall.evallweb.portlet.evaluate.system.download=Download
es.uned.nlp.evall.evallweb.portlet.evaluate.system.description=Description
es.uned.nlp.evall.evallweb.portlet.evaluate.evaluation.option.title=Select the configuration for the evaluation
es.uned.nlp.evall.evallweb.portlet.evaluate.evaluation.option.default=Recommended configuration. EvALL will select the appropriate settings for you.
es.uned.nlp.evall.evallweb.portlet.evaluate.evaluation.option.custom=Choose the configuration that best suits.
es.uned.nlp.evall.evallweb.portlet.evaluate.metric.option.title=Select the set of metrics for the evaluation
es.uned.nlp.evall.evallweb.portlet.evaluate.metric.option.official.title=Official set of metrics
es.uned.nlp.evall.evallweb.portlet.evaluate.metric.option.full.title=Full set of metrics
es.uned.nlp.evall.evallweb.portlet.evaluate.metric.option.custom.title=Customized set of metrics
es.uned.nlp.evall.evallweb.portlet.evaluate.metric.option.official.text=Those prescribed in the test collection / evaluation campaign.
es.uned.nlp.evall.evallweb.portlet.evaluate.metric.option.full.text=Including official evaluation metrics and also all metrics recommended by the EvALL toolkit.
es.uned.nlp.evall.evallweb.portlet.evaluate.metric.option.custom.text=Choose the set of metrics you want to consider, or set the parameters of the metrics.
es.uned.nlp.evall.evallweb.portlet.evaluate.baseline.option.title=Select from the EvALL repository the system to be compared
es.uned.nlp.evall.evallweb.portlet.evaluate.baseline.option.best.title=Best system in EvALL repository
es.uned.nlp.evall.evallweb.portlet.evaluate.baseline.option.select.title=Select the system from the EvALL repository
es.uned.nlp.evall.evallweb.portlet.evaluate.baseline.option.best.text=Best and average system in the EvALL repository for this benchmark.
es.uned.nlp.evall.evallweb.portlet.evaluate.baseline.option.select.text=Select the system from the list of systems stored in EvALL for this benchmark.
es.uned.nlp.evall.evallweb.portlet.evaluate.system.field.name=Name
es.uned.nlp.evall.evallweb.portlet.evaluate.system.field.title=Title
es.uned.nlp.evall.evallweb.portlet.evaluate.system.field.description=Description
es.uned.nlp.evall.evallweb.portlet.evaluate.system.field.author=Author
es.uned.nlp.evall.evallweb.portlet.evaluate.system.field.paper=Paper
es.uned.nlp.evall.evallweb.portlet.evaluate.system.field.date=Date
es.uned.nlp.evall.evallweb.portlet.evaluate.pagination.arrow.left=&#10094;
es.uned.nlp.evall.evallweb.portlet.evaluate.pagination.arrow.right=&#10095;
es.uned.nlp.evall.evallweb.portlet.evaluate.report.option.title=Select the settings for the evaluation report
es.uned.nlp.evall.evallweb.portlet.evaluate.report.option.pdf.title=Generate pdf/latex report
es.uned.nlp.evall.evallweb.portlet.evaluate.report.option.tsv.title=Generate tsv report
es.uned.nlp.evall.evallweb.portlet.evaluate.report.option.descriptions.title=Add metric descriptions
es.uned.nlp.evall.evallweb.portlet.evaluate.report.option.warnings.title=Add output verifications
es.uned.nlp.evall.evallweb.portlet.evaluate.report.option.pdf.text=Generate pdf/lates report.
es.uned.nlp.evall.evallweb.portlet.evaluate.report.option.tsv.text=Generate tsv report.
es.uned.nlp.evall.evallweb.portlet.evaluate.report.option.descriptions.text=Include explanations and definitions for each of the metrics.
es.uned.nlp.evall.evallweb.portlet.evaluate.report.option.warnings.text=Include the results of the verification step for each of the inputs you provide (with warnings in case of inconsistent format).
es.uned.nlp.evall.evallweb.portlet.evaluate.upload.title=Upload the desired system outputs
es.uned.nlp.evall.evallweb.portlet.evaluate.upload.field.name=File Name
es.uned.nlp.evall.evallweb.portlet.evaluate.upload.field.size=File Size
es.uned.nlp.evall.evallweb.portlet.evaluate.upload.field.progress=Progress
es.uned.nlp.evall.evallweb.portlet.evaluate.upload.browse=Upload an output
es.uned.nlp.evall.evallweb.portlet.evaluate.upload.browse.bibtex=Upload a bibtex
es.uned.nlp.evall.evallweb.portlet.evaluate.upload.load.example=Load a random sample from repository
es.uned.nlp.evall.evallweb.portlet.evaluate.upload.or=or
es.uned.nlp.evall.evallweb.portlet.evaluate.upload.dragAndDrop=Drag and drop
es.uned.nlp.evall.evallweb.portlet.evaluate.upload.evaluate=Evaluate
es.uned.nlp.evall.evallweb.portlet.evaluate.result.title=Results of the evaluation for the selected configuration
es.uned.nlp.evall.evallweb.portlet.evaluate.result.report=Report
es.uned.nlp.evall.evallweb.portlet.evaluate.result.latex=Latex project
es.uned.nlp.evall.evallweb.portlet.evaluate.result.tsv=TSV files
es.uned.nlp.evall.evallweb.portlet.evaluate.save.title=Save uploaded outputs
es.uned.nlp.evall.evallweb.portlet.evaluate.save.delete.author=X
es.uned.nlp.evall.evallweb.portlet.evaluate.save.author.name=Name
es.uned.nlp.evall.evallweb.portlet.evaluate.save.author.surname=Surname
es.uned.nlp.evall.evallweb.portlet.evaluate.save.uploading.bibtex=uploading BibTex...
es.uned.nlp.evall.evallweb.portlet.evaluate.cookie.error.message=Failed to modify the cookie...
es.uned.nlp.evall.evallweb.portlet.evaluate.save.error.message=has not been able to save.
es.uned.nlp.evall.evallweb.portlet.evaluate.save.success.message=has been successfully saved.
es.uned.nlp.evall.evallweb.portlet.evaluate.save.author.character.message1=Characters "
es.uned.nlp.evall.evallweb.portlet.evaluate.save.author.character.message2=" are not allowed
es.uned.nlp.evall.evallweb.portlet.evaluate.save.author.duplicate.message1=Author
es.uned.nlp.evall.evallweb.portlet.evaluate.save.author.duplicate.message2=already exists
es.uned.nlp.evall.evallweb.portlet.evaluate.noviewer=No preview